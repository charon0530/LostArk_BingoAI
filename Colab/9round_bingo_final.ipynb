{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"9round_bingo_final.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"0QCKARKGkCpF","executionInfo":{"status":"ok","timestamp":1655937194662,"user_tz":-540,"elapsed":356,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"outputs":[],"source":["from gym import Env\n","from gym.spaces import Discrete, Box\n","import numpy as np\n"]},{"cell_type":"code","source":["from collections import deque\n","\n","def BFS(board, start_row, start_col):\n","  level = [[0]*5 for i in range(5)]\n","  #Stay Up Right Down Left, UR, DR, DL, UL\n","  dr = [0,-1,0,1,0, -1,1,1,-1]\n","  dc = [0,0,1,0,-1,1,1,-1,-1]\n","\n","  result = 0\n","  if board[start_row][start_col] == 1 or board[start_row][start_col] == 2:\n","    return 0\n","\n","  queue = deque([])\n","  visited = [[False]*5 for i in range(5)]\n","  \n","  level[start_row][start_col] = 1\n","  visited[start_row][start_col] = True\n","  queue.append((start_row,start_col))\n","\n","  while(len(queue) != 0):\n","    (row,col) = queue.popleft()\n","    #result = result + 1\n","    result = result + (10-level[row][col])*5\n","\n","    for i in range(9):\n","      nr = row + dr[i]\n","      nc = col + dc[i]\n","      if nr < 0 or nr >= 5 or nc < 0 or nc >= 5:\n","        continue\n","      if board[nr][nc] == 1 or board[nr][nc] == 2: #여기수정\n","        continue\n","      if visited[nr][nc] == True:\n","        continue\n","\n","      visited[nr][nc] = True\n","      if i<=4:\n","        level[nr][nc] = level[row][col] +1\n","      else:\n","        level[nr][nc] = level[row][col] +1+0.5\n","      queue.append((nr,nc))\n","\n","  return result\n","\n","\n","temp = [[0]*5 for i in range(5)]\n","\n","BFS(temp,1,1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRe5IAuKE-BQ","outputId":"421878e7-f231-4ff0-973c-279f35a63e4d","executionInfo":{"status":"ok","timestamp":1655937194662,"user_tz":-540,"elapsed":6,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["827.5"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import copy\n","from tabulate import tabulate\n","import random\n","\n","class BingoEnv(Env):\n","  def __init__(self):\n","    self.round = 0\n","    self.action_space = Discrete(25)\n","    #self.observation_space = Box(low=0, high=2, shape=(15,5,5), dtype=np.int32)\n","    self.observation_space = Box(low = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]), high = np.array([2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,10]),dtype=np.int32)\n"," \n","    #self.state = np.zeros((15,5,5))\n","    self.state = np.zeros(26)\n","    \n","    self.first_rand_pos = random.choice([i for i in range(0,25) if i not in [6]])\n","    self.second_rand_pos = random.choice([i for i in range(0,25) if i not in [6,self.first_rand_pos]])\n","    self.state[self.first_rand_pos] = 1\n","    self.state[self.second_rand_pos] = 1\n","\n","\n","\n","  def check_bingo(self, board, row,col):\n","    result_list = []\n","\n","    result = 1\n","    for i in range(5):\n","      result = result * board[row][i]\n","      if result == 0:\n","        break\n","    if result > 0:\n","      result_list.append(\"ROW\")\n","    \n","    result = 1\n","    for i in range(5):\n","      result = result * board[i][col]\n","      if result == 0:\n","        break\n","    if result > 0:\n","      result_list.append(\"COL\")\n","\n","    if row == col:\n","      result = 1\n","      result = result * board[0][0] * board[1][1] * board[2][2] * board[3][3] * board[4][4]\n","      if result > 0:\n","        result_list.append(\"LC\")\n","\n","    if row+col == 4:\n","      result = 1\n","      result = result * board[0][4] * board[1][3] * board[2][2] * board[3][1] * board[4][0]\n","      if result > 0 :\n","        result_list.append(\"RC\")\n","\n","    return result_list\n","\n","  def step(self, action):\n","    #self.round = self.round+1\n","    #cur_board = self.state[self.round]\n","    #self.state[self.round] = copy.deepcopy(self.state[self.round-1])\n","    self.round = self.state[-1] + 1\n","    self.state = self.state[:-1].reshape(5,5)\n","    row = action // 5\n","    col = action % 5\n","    bingo_count = 0\n","    #canClick = False\n","\n","#None Up Right Down Left\n","    dr = [0,-1,0,1,0]\n","    dc = [0,0,1,0,-1]\n","    before_num = [-1,-1,-1,-1,-1]\n","    for i in range(5):\n","      nr = row + dr[i]\n","      nc = col + dc[i]\n","      if nr < 0 or nr >= 5 or nc < 0 or nc >= 5:\n","        continue\n","\n","      if self.state[nr][nc] == 2:\n","        before_num[i] = 2\n","        continue\n","\n","      elif self.state[nr][nc] == 1:\n","        before_num[i] = 1\n","        self.state[nr][nc] = 0\n","        \n","      elif self.state[nr][nc] == 0:\n","        before_num[i] = 0\n","        self.state[nr][nc] = 1\n","      \n","    for i in range(5):\n","      nr = row + dr[i]\n","      nc = col + dc[i]\n","      if before_num[i] == 2:\n","        continue\n","      if nr < 0 or nr >= 5 or nc < 0 or nc >= 5:\n","        continue\n","\n","      if self.state[nr][nc] != 0:\n","        isBingo = self.check_bingo(self.state,nr,nc)\n","        bingo_count = bingo_count + len(isBingo)\n","\n","        for dir in isBingo:\n","          if dir == \"ROW\":\n","            for i in range(5):\n","              self.state[nr][i] = 2\n","          elif dir == \"COL\":\n","            for i in range(5):\n","              self.state[i][nc] = 2\n","          elif dir == \"LC\":\n","            self.state[0][0] = 2\n","            self.state[1][1] = 2\n","            self.state[2][2] = 2\n","            self.state[3][3] = 2\n","            self.state[4][4] = 2\n","          elif dir == \"RC\":\n","            self.state[0][4] = 2\n","            self.state[1][3] = 2\n","            self.state[2][2] = 2\n","            self.state[3][1] = 2\n","            self.state[4][0] = 2\n","    \n","    \n","    three_bingo = True\n","    #rest_block_score = BFS(self.state,1,1) / 100\n","    #rest_block_score = BFS(self.state,1,1) / 50\n","    rest_block_score = BFS(self.state,1,1) / 10\n","\n","    if self.round % 3 == 0 and bingo_count == 0:\n","      three_bingo = False\n","    else:\n","      reward = rest_block_score\n","    #elif self.round % 3 == 0 and bingo_count > 0:\n","    #  reward = (2/bingo_count) + rest_block_score\n","    #elif self.round % 3 != 0 and bingo_count > 0:\n","    #  reward = -0.5 * bingo_count + rest_block_score\n","    #else:\n","    #  reward = rest_block_score\n","\n","    board_sum = 0\n","    for i in range(5):\n","      for j in range(5):\n","        board_sum = board_sum + self.state[i][j]\n","\n","    if (board_sum == 50) or self.round == 9 or three_bingo == False:\n","      done = True\n","      if self.round == 9 and three_bingo == True:\n","        reward = rest_block_score\n","      else:\n","        reward = -100\n","    else:\n","      done = False\n","    \n","    #if done == False:\n","    #  reward += 1\n","    \n","    info ={}\n","    self.state = np.append(self.state.reshape(25),self.round)\n","    return self.state, reward, done, info\n","\n","  def render(self):\n","    print(\"ROUND : \",self.state[-1])\n","    print(tabulate(self.state[0:25].reshape(5,5)))\n","\n","  def reset(self):\n","    self.state = np.zeros(26)\n","    \n","    self.first_rand_pos = random.choice([i for i in range(0,25) if i not in [6]])\n","    self.second_rand_pos = random.choice([i for i in range(0,25) if i not in [6,self.first_rand_pos]])\n","    self.state[self.first_rand_pos] = 1\n","    self.state[self.second_rand_pos] = 1\n","    return self.state\n","\n","\n","#t = BingoEnv()\n","#t.render()\n","#t.step(0)\n","#t.step(3)\n","#t.step(9)\n","#t.step(24)"],"metadata":{"id":"GWtJ-MHErlCG","executionInfo":{"status":"ok","timestamp":1655937195004,"user_tz":-540,"elapsed":346,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["a= np.array([5,4,3])\n","a = a[-1] + 7\n","print(a)\n","np.zeros((1,5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KNWYuguXE9Eu","outputId":"d8f8d169-f053-4631-e23b-3950b161a7cf","executionInfo":{"status":"ok","timestamp":1655937195465,"user_tz":-540,"elapsed":9,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["10\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0.]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["env = BingoEnv()\n","episodes = 10\n","for episode in range(1,episodes+1):\n","  state = env.reset()\n","  done = False\n","  reward_sum = 0\n","\n","  while not done:\n","    env.render()\n","    action = env.action_space.sample()\n","    n_state, reward, done, info = env.step(action)\n","    reward_sum += reward\n","\n","  env.render()\n","  print(\"Episode : {} reward_sum : {}\".format(episode, reward_sum))"],"metadata":{"id":"RIVgMTe6IhCe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ece80aca-5064-4360-8fda-e7b918d5ff45","executionInfo":{"status":"ok","timestamp":1655937195466,"user_tz":-540,"elapsed":8,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["ROUND :  0.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  0  0  0  0\n","0  0  0  0  0\n","0  1  0  0  0\n","0  0  0  1  0\n","-  -  -  -  -\n","ROUND :  1.0\n","-  -  -  -  -\n","0  0  1  1  1\n","0  0  0  1  0\n","0  0  0  0  0\n","0  1  0  0  0\n","0  0  0  1  0\n","-  -  -  -  -\n","ROUND :  2.0\n","-  -  -  -  -\n","0  0  1  1  1\n","0  0  0  1  0\n","0  0  0  0  0\n","0  1  0  0  1\n","0  0  0  0  1\n","-  -  -  -  -\n","ROUND :  3.0\n","-  -  -  -  -\n","0  0  1  1  1\n","0  0  0  1  0\n","0  1  0  0  0\n","1  0  1  0  1\n","0  1  0  0  1\n","-  -  -  -  -\n","Episode : 1 reward_sum : 22.75\n","ROUND :  0.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  0  0  0  0\n","1  0  0  0  0\n","1  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  1.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  1  0  0  0\n","0  1  1  0  0\n","1  1  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  2.0\n","-  -  -  -  -\n","0  0  1  1  1\n","0  1  0  1  0\n","0  1  1  0  0\n","1  1  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  3.0\n","-  -  -  -  -\n","0  1  1  1  1\n","1  0  1  1  0\n","0  0  1  0  0\n","1  1  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","Episode : 2 reward_sum : -100.0\n","ROUND :  0.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  0  0  0  1\n","0  0  0  0  0\n","0  0  0  0  1\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  1.0\n","-  -  -  -  -\n","0  0  0  0  1\n","0  0  0  1  0\n","0  0  0  0  1\n","0  0  0  0  1\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  2.0\n","-  -  -  -  -\n","0  0  0  0  1\n","0  1  0  1  0\n","1  1  1  0  1\n","0  1  0  0  1\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  3.0\n","-  -  -  -  -\n","0  0  0  0  1\n","0  1  0  1  0\n","1  1  1  0  1\n","0  0  0  0  1\n","1  1  1  0  0\n","-  -  -  -  -\n","Episode : 3 reward_sum : -29.25\n","ROUND :  0.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  0  0  0  1\n","0  0  0  0  0\n","0  1  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  1.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  1  0  0  1\n","1  1  1  0  0\n","0  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  2.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  1  0  0  1\n","1  1  1  1  0\n","0  0  1  1  1\n","0  0  0  1  0\n","-  -  -  -  -\n","ROUND :  3.0\n","-  -  -  -  -\n","0  0  0  0  0\n","1  1  0  0  1\n","0  0  1  1  0\n","1  0  1  1  1\n","0  0  0  1  0\n","-  -  -  -  -\n","Episode : 4 reward_sum : -100.0\n","ROUND :  0.0\n","-  -  -  -  -\n","0  0  0  0  1\n","0  0  0  0  0\n","0  0  0  0  0\n","0  0  0  0  1\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  1.0\n","-  -  -  -  -\n","0  0  0  0  1\n","0  0  0  0  0\n","0  0  1  0  0\n","0  1  1  1  1\n","0  0  1  0  0\n","-  -  -  -  -\n","ROUND :  2.0\n","-  -  -  -  -\n","1  1  1  0  1\n","0  1  0  0  0\n","0  0  1  0  0\n","0  1  1  1  1\n","0  0  1  0  0\n","-  -  -  -  -\n","ROUND :  3.0\n","-  -  -  -  -\n","1  1  1  0  1\n","0  1  0  0  0\n","0  0  1  1  0\n","0  1  0  0  0\n","0  0  1  1  0\n","-  -  -  -  -\n","Episode : 5 reward_sum : -44.0\n","ROUND :  0.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  0  1  0  0\n","0  0  1  0  0\n","0  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  1.0\n","-  -  -  -  -\n","0  0  1  1  1\n","0  0  1  1  0\n","0  0  1  0  0\n","0  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  2.0\n","-  -  -  -  -\n","0  0  1  1  2\n","0  0  1  2  0\n","1  0  2  0  0\n","1  2  0  0  0\n","2  0  0  0  0\n","-  -  -  -  -\n","ROUND :  3.0\n","-  -  -  -  -\n","0  0  1  1  2\n","0  0  1  2  1\n","1  0  2  0  1\n","1  2  0  0  0\n","2  0  0  0  0\n","-  -  -  -  -\n","Episode : 6 reward_sum : 2.75\n","ROUND :  0.0\n","-  -  -  -  -\n","0  1  1  0  0\n","0  0  0  0  0\n","0  0  0  0  0\n","0  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  1.0\n","-  -  -  -  -\n","0  1  1  1  0\n","0  0  1  1  1\n","0  0  0  1  0\n","0  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  2.0\n","-  -  -  -  -\n","0  1  1  1  0\n","1  0  1  1  1\n","1  1  0  1  0\n","1  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  3.0\n","-  -  -  -  -\n","0  0  1  1  0\n","0  1  0  1  1\n","1  0  0  1  0\n","1  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","Episode : 7 reward_sum : -7.0\n","ROUND :  0.0\n","-  -  -  -  -\n","0  0  1  0  0\n","0  0  0  0  0\n","0  0  1  0  0\n","0  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  1.0\n","-  -  -  -  -\n","0  0  1  0  0\n","0  0  0  0  0\n","0  0  1  0  0\n","0  1  0  0  0\n","1  1  1  0  0\n","-  -  -  -  -\n","ROUND :  2.0\n","-  -  -  -  -\n","0  0  1  0  0\n","0  0  0  0  1\n","0  0  1  1  1\n","0  1  0  0  1\n","1  1  1  0  0\n","-  -  -  -  -\n","ROUND :  3.0\n","-  -  -  -  -\n","0  0  1  0  0\n","0  0  0  0  1\n","0  0  0  1  1\n","0  0  1  1  1\n","1  1  0  0  0\n","-  -  -  -  -\n","Episode : 8 reward_sum : 14.0\n","ROUND :  0.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  0  0  0  0\n","1  0  0  1  0\n","0  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  1.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  0  0  0  0\n","1  0  0  0  0\n","0  0  1  1  1\n","0  0  0  1  0\n","-  -  -  -  -\n","ROUND :  2.0\n","-  -  -  -  -\n","1  0  0  0  0\n","1  1  0  0  0\n","0  0  0  0  0\n","0  0  1  1  1\n","0  0  0  1  0\n","-  -  -  -  -\n","ROUND :  3.0\n","-  -  -  -  -\n","1  0  0  0  0\n","0  1  0  0  0\n","1  1  0  0  0\n","1  0  1  1  1\n","0  0  0  1  0\n","-  -  -  -  -\n","Episode : 9 reward_sum : -34.5\n","ROUND :  0.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  0  1  0  0\n","1  0  0  0  0\n","0  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  1.0\n","-  -  -  -  -\n","0  1  0  0  0\n","1  1  0  0  0\n","1  1  0  0  0\n","0  0  0  0  0\n","0  0  0  0  0\n","-  -  -  -  -\n","ROUND :  2.0\n","-  -  -  -  -\n","0  1  0  0  0\n","1  1  0  0  0\n","1  1  0  0  0\n","0  0  1  0  0\n","0  1  1  1  0\n","-  -  -  -  -\n","ROUND :  3.0\n","-  -  -  -  -\n","0  1  0  1  1\n","1  1  0  0  1\n","1  1  0  0  0\n","0  0  1  0  0\n","0  1  1  1  0\n","-  -  -  -  -\n","Episode : 10 reward_sum : -100.0\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.optimizers import Adam"],"metadata":{"id":"yAOwbl_DFwPj","executionInfo":{"status":"ok","timestamp":1655937199134,"user_tz":-540,"elapsed":3673,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def build_model(states, actions):\n","  model = Sequential()\n","  model.add(Flatten(input_shape=(1,26)))\n","  model.add(Dense(50, activation='relu'))\n","  model.add(Dense(50, activation='relu'))\n","  model.add(Dense(actions,activation='linear'))\n","  return model"],"metadata":{"id":"Zyb0OJBY_o1M","executionInfo":{"status":"ok","timestamp":1655937199473,"user_tz":-540,"elapsed":8,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["del model"],"metadata":{"id":"Jc9v1Rk5Ocro","executionInfo":{"status":"ok","timestamp":1655937220401,"user_tz":-540,"elapsed":312,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["states = env.observation_space.shape\n","actions = env.action_space.n\n","model = build_model(states,actions)\n"],"metadata":{"id":"-4tDsQDyHmDr","executionInfo":{"status":"ok","timestamp":1655937227645,"user_tz":-540,"elapsed":305,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["model.summary()\n","states"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHaCCRzNIfmW","outputId":"942883d1-6eed-49b1-9261-42638b6593d2","executionInfo":{"status":"ok","timestamp":1655937229962,"user_tz":-540,"elapsed":397,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_1 (Flatten)         (None, 26)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 50)                1350      \n","                                                                 \n"," dense_4 (Dense)             (None, 50)                2550      \n","                                                                 \n"," dense_5 (Dense)             (None, 25)                1275      \n","                                                                 \n","=================================================================\n","Total params: 5,175\n","Trainable params: 5,175\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"execute_result","data":{"text/plain":["(26,)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["!pip install keras-rl2"],"metadata":{"id":"881JhgDgJI0W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655937212891,"user_tz":-540,"elapsed":7626,"user":{"displayName":"GH K","userId":"01062405385549991714"}},"outputId":"144b18b7-da3c-4861-f6aa-de6f2558f8de"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-rl2\n","  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 323 kB/s \n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.8.2+zzzcolab20220527125636)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (4.1.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (57.4.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.46.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n","Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.26.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.1.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.21.6)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (14.0.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-rl2) (1.5.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.2.0)\n","Installing collected packages: keras-rl2\n","Successfully installed keras-rl2-1.0.5\n"]}]},{"cell_type":"code","source":["from rl.agents import DQNAgent\n","from rl.policy import BoltzmannQPolicy\n","from rl.memory import SequentialMemory\n","from rl.policy import EpsGreedyQPolicy\n","\n","def build_agent(model, actions):\n","  policy = BoltzmannQPolicy()\n","  memory = SequentialMemory(limit=50000,window_length=1)\n","  dqn = DQNAgent(model= model, memory = memory, policy= policy, nb_actions=actions, nb_steps_warmup=1000,target_model_update=1e-2)\n","  return dqn"],"metadata":{"id":"VsLoHQdvJtnP","executionInfo":{"status":"ok","timestamp":1655937319017,"user_tz":-540,"elapsed":305,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["dqn = build_agent(model, actions)\n","dqn.compile(Adam(learning_rate=0.0005), metrics=[\"mse\"])\n","#dqn.fit(env,nb_steps = 200000, visualize= False, verbose=1) #  더 학습시킬 때는 아래 있는 코드를 이용해라!!!!!"],"metadata":{"id":"YyJrYP7tKXnQ","executionInfo":{"status":"ok","timestamp":1655937326747,"user_tz":-540,"elapsed":784,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["scores = dqn.test(env, nb_episodes=100, visualize=False)\n","print(np.mean(scores.history['episode_reward']))"],"metadata":{"id":"yZpwrPDRVfiG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655940069492,"user_tz":-540,"elapsed":991,"user":{"displayName":"GH K","userId":"01062405385549991714"}},"outputId":"15e90553-67f9-4130-e77d-d99afba2306a"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing for 100 episodes ...\n","Episode 1: reward: 354.250, steps: 9\n","Episode 2: reward: 394.000, steps: 9\n","Episode 3: reward: 364.750, steps: 9\n","Episode 4: reward: 421.250, steps: 9\n","Episode 5: reward: 390.250, steps: 9\n","Episode 6: reward: 410.750, steps: 9\n","Episode 7: reward: 384.500, steps: 9\n","Episode 8: reward: 239.750, steps: 9\n","Episode 9: reward: 393.750, steps: 9\n","Episode 10: reward: 359.250, steps: 9\n","Episode 11: reward: 177.750, steps: 6\n","Episode 12: reward: 394.250, steps: 9\n","Episode 13: reward: 403.000, steps: 9\n","Episode 14: reward: 377.750, steps: 9\n","Episode 15: reward: 403.000, steps: 9\n","Episode 16: reward: 254.000, steps: 9\n","Episode 17: reward: 399.500, steps: 9\n","Episode 18: reward: 400.500, steps: 9\n","Episode 19: reward: 383.250, steps: 9\n","Episode 20: reward: 389.750, steps: 9\n","Episode 21: reward: 378.500, steps: 9\n","Episode 22: reward: 360.750, steps: 9\n","Episode 23: reward: 328.000, steps: 9\n","Episode 24: reward: 344.750, steps: 9\n","Episode 25: reward: 408.500, steps: 9\n","Episode 26: reward: 344.750, steps: 9\n","Episode 27: reward: 416.750, steps: 9\n","Episode 28: reward: 384.500, steps: 9\n","Episode 29: reward: 324.750, steps: 9\n","Episode 30: reward: 367.500, steps: 9\n","Episode 31: reward: 355.000, steps: 9\n","Episode 32: reward: 398.500, steps: 9\n","Episode 33: reward: 329.000, steps: 9\n","Episode 34: reward: 369.250, steps: 9\n","Episode 35: reward: 373.500, steps: 9\n","Episode 36: reward: 360.000, steps: 9\n","Episode 37: reward: 373.500, steps: 9\n","Episode 38: reward: 215.500, steps: 6\n","Episode 39: reward: 419.000, steps: 9\n","Episode 40: reward: 409.750, steps: 9\n","Episode 41: reward: 326.750, steps: 9\n","Episode 42: reward: 384.000, steps: 9\n","Episode 43: reward: 360.750, steps: 9\n","Episode 44: reward: 375.750, steps: 9\n","Episode 45: reward: 373.500, steps: 9\n","Episode 46: reward: 328.000, steps: 9\n","Episode 47: reward: 413.250, steps: 9\n","Episode 48: reward: 414.250, steps: 9\n","Episode 49: reward: 384.500, steps: 9\n","Episode 50: reward: 411.000, steps: 9\n","Episode 51: reward: 396.000, steps: 9\n","Episode 52: reward: 376.250, steps: 9\n","Episode 53: reward: 367.000, steps: 9\n","Episode 54: reward: 421.250, steps: 9\n","Episode 55: reward: 196.250, steps: 6\n","Episode 56: reward: 369.250, steps: 9\n","Episode 57: reward: 341.000, steps: 9\n","Episode 58: reward: 420.000, steps: 9\n","Episode 59: reward: 184.750, steps: 6\n","Episode 60: reward: 383.250, steps: 9\n","Episode 61: reward: 389.750, steps: 9\n","Episode 62: reward: 406.500, steps: 9\n","Episode 63: reward: 378.500, steps: 9\n","Episode 64: reward: 442.250, steps: 9\n","Episode 65: reward: 412.250, steps: 9\n","Episode 66: reward: 368.500, steps: 9\n","Episode 67: reward: 402.000, steps: 9\n","Episode 68: reward: 329.000, steps: 9\n","Episode 69: reward: 357.750, steps: 9\n","Episode 70: reward: 333.750, steps: 9\n","Episode 71: reward: 371.500, steps: 9\n","Episode 72: reward: 338.500, steps: 9\n","Episode 73: reward: 406.500, steps: 9\n","Episode 74: reward: 368.500, steps: 9\n","Episode 75: reward: 360.750, steps: 9\n","Episode 76: reward: 397.000, steps: 9\n","Episode 77: reward: 337.500, steps: 9\n","Episode 78: reward: 357.000, steps: 9\n","Episode 79: reward: 254.750, steps: 9\n","Episode 80: reward: 410.750, steps: 9\n","Episode 81: reward: 334.000, steps: 9\n","Episode 82: reward: 456.000, steps: 9\n","Episode 83: reward: 421.250, steps: 9\n","Episode 84: reward: 334.000, steps: 9\n","Episode 85: reward: 409.250, steps: 9\n","Episode 86: reward: 403.750, steps: 9\n","Episode 87: reward: 382.250, steps: 9\n","Episode 88: reward: 292.000, steps: 9\n","Episode 89: reward: 337.250, steps: 9\n","Episode 90: reward: 329.000, steps: 9\n","Episode 91: reward: 373.250, steps: 9\n","Episode 92: reward: 409.750, steps: 9\n","Episode 93: reward: 349.000, steps: 9\n","Episode 94: reward: 357.000, steps: 9\n","Episode 95: reward: 379.750, steps: 9\n","Episode 96: reward: 329.000, steps: 9\n","Episode 97: reward: 395.250, steps: 9\n","Episode 98: reward: 369.500, steps: 9\n","Episode 99: reward: 390.250, steps: 9\n","Episode 100: reward: 364.750, steps: 9\n","366.23\n"]}]},{"cell_type":"code","source":["model.save('9round_final.h5')"],"metadata":{"id":"aM4YltWqiGph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dqn.fit(env,nb_steps = 200000, visualize= False, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_hys_wpirWw","outputId":"6d7eaf67-afe0-47c0-8e0f-82d020f9e7b9","executionInfo":{"status":"ok","timestamp":1655940009217,"user_tz":-540,"elapsed":1282470,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Training for 200000 steps ...\n","Interval 1 (0 steps performed)\n","10000/10000 [==============================] - 14s 1ms/step - reward: 37.5416\n","1178 episodes - episode_reward: 318.481 [16.500, 445.500]\n","\n","Interval 2 (10000 steps performed)\n","10000/10000 [==============================] - 15s 1ms/step - reward: 37.2053\n","1192 episodes - episode_reward: 312.085 [16.500, 445.500]\n","\n","Interval 3 (20000 steps performed)\n","10000/10000 [==============================] - 14s 1ms/step - reward: 37.2801\n","1187 episodes - episode_reward: 314.170 [16.500, 445.500]\n","\n","Interval 4 (30000 steps performed)\n","10000/10000 [==============================] - 14s 1ms/step - reward: 37.4971\n","1179 episodes - episode_reward: 317.919 [16.500, 445.500]\n","\n","Interval 5 (40000 steps performed)\n","10000/10000 [==============================] - 14s 1ms/step - reward: 36.8883\n","1187 episodes - episode_reward: 310.681 [16.500, 445.500]\n","\n","Interval 6 (50000 steps performed)\n","10000/10000 [==============================] - 14s 1ms/step - reward: 37.4034\n","1179 episodes - episode_reward: 317.345 [16.500, 445.500]\n","\n","Interval 7 (60000 steps performed)\n","10000/10000 [==============================] - 14s 1ms/step - reward: 37.5894\n","1175 episodes - episode_reward: 320.116 [16.500, 445.500]\n","\n","Interval 8 (70000 steps performed)\n","10000/10000 [==============================] - 14s 1ms/step - reward: 37.3411\n","1173 episodes - episode_reward: 318.055 [16.500, 445.500]\n","\n","Interval 9 (80000 steps performed)\n","10000/10000 [==============================] - 14s 1ms/step - reward: 37.3437\n","1178 episodes - episode_reward: 317.198 [16.500, 445.500]\n","\n","Interval 10 (90000 steps performed)\n","10000/10000 [==============================] - 14s 1ms/step - reward: 36.9479\n","1180 episodes - episode_reward: 313.207 [16.500, 445.500]\n","\n","Interval 11 (100000 steps performed)\n","10000/10000 [==============================] - 116s 12ms/step - reward: 37.7820\n","1199 episodes - episode_reward: 315.064 [16.500, 445.500] - loss: 236.580 - mse: 10187.173 - mean_q: 128.442\n","\n","Interval 12 (110000 steps performed)\n","10000/10000 [==============================] - 117s 12ms/step - reward: 38.6062\n","1171 episodes - episode_reward: 329.547 [19.500, 445.500] - loss: 206.601 - mse: 12989.104 - mean_q: 132.277\n","\n","Interval 13 (120000 steps performed)\n","10000/10000 [==============================] - 117s 12ms/step - reward: 39.5538\n","1163 episodes - episode_reward: 340.172 [20.000, 445.500] - loss: 196.244 - mse: 16206.108 - mean_q: 135.487\n","\n","Interval 14 (130000 steps performed)\n","10000/10000 [==============================] - 116s 12ms/step - reward: 39.8782\n","1152 episodes - episode_reward: 346.114 [20.000, 456.000] - loss: 178.195 - mse: 20900.238 - mean_q: 139.199\n","\n","Interval 15 (140000 steps performed)\n","10000/10000 [==============================] - 113s 11ms/step - reward: 39.8417\n","1144 episodes - episode_reward: 348.227 [-36.250, 460.000] - loss: 161.239 - mse: 28028.822 - mean_q: 142.950\n","\n","Interval 16 (150000 steps performed)\n","10000/10000 [==============================] - 116s 12ms/step - reward: 40.3850\n","1142 episodes - episode_reward: 353.845 [-36.250, 457.750] - loss: 135.278 - mse: 35362.984 - mean_q: 146.125\n","\n","Interval 17 (160000 steps performed)\n","10000/10000 [==============================] - 115s 12ms/step - reward: 40.9528\n","1138 episodes - episode_reward: 359.817 [15.750, 456.000] - loss: 112.003 - mse: 42721.215 - mean_q: 148.419\n","\n","Interval 18 (170000 steps performed)\n","10000/10000 [==============================] - 109s 11ms/step - reward: 41.3654\n","1138 episodes - episode_reward: 363.442 [15.750, 456.000] - loss: 90.638 - mse: 51571.625 - mean_q: 152.595\n","\n","Interval 19 (180000 steps performed)\n","10000/10000 [==============================] - 113s 11ms/step - reward: 41.4342\n","1134 episodes - episode_reward: 365.235 [15.750, 456.000] - loss: 76.867 - mse: 61630.398 - mean_q: 154.966\n","\n","Interval 20 (190000 steps performed)\n","10000/10000 [==============================] - 111s 11ms/step - reward: 41.5845\n","done, took 1282.262 seconds\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fa9c1786d50>"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["-4.5"],"metadata":{"id":"hDNAuT35wI0K"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"giJEOjBlvuqw"}},{"cell_type":"code","source":["class TestBingoEnv(Env):\n","  def __init__(self,state):\n","    self.round = state[-1]\n","    self.action_space = Discrete(25)\n","    self.observation_space = Box(low = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]), high = np.array([2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,10]),dtype=np.int32)\n","    self.state = state\n","\n","\n","\n","  def check_bingo(self, board, row,col):\n","    result_list = []\n","\n","    result = 1\n","    for i in range(5):\n","      result = result * board[row][i]\n","      if result == 0:\n","        break\n","    if result > 0:\n","      result_list.append(\"ROW\")\n","    \n","    result = 1\n","    for i in range(5):\n","      result = result * board[i][col]\n","      if result == 0:\n","        break\n","    if result > 0:\n","      result_list.append(\"COL\")\n","\n","    if row == col:\n","      result = 1\n","      result = result * board[0][0] * board[1][1] * board[2][2] * board[3][3] * board[4][4]\n","      if result > 0:\n","        result_list.append(\"LC\")\n","\n","    if row+col == 4:\n","      result = 1\n","      result = result * board[0][4] * board[1][3] * board[2][2] * board[3][1] * board[4][0]\n","      if result > 0 :\n","        result_list.append(\"RC\")\n","\n","    return result_list\n","\n","  def step(self, action):\n","    #self.round = self.round+1\n","    #cur_board = self.state[self.round]\n","    #self.state[self.round] = copy.deepcopy(self.state[self.round-1])\n","    self.round = self.state[-1] + 1\n","    self.state = self.state[:-1].reshape(5,5)\n","    row = action // 5\n","    col = action % 5\n","    bingo_count = 0\n","    canClick = False\n","\n","#None Up Right Down Left\n","    dr = [0,-1,0,1,0]\n","    dc = [0,0,1,0,-1]\n","    before_num = [-1,-1,-1,-1,-1]\n","    for i in range(5):\n","      nr = row + dr[i]\n","      nc = col + dc[i]\n","      if nr < 0 or nr >= 5 or nc < 0 or nc >= 5:\n","        continue\n","\n","      if self.state[nr][nc] == 2:\n","        before_num[i] = 2\n","        continue\n","\n","      elif self.state[nr][nc] == 1:\n","        before_num[i] = 1\n","        self.state[nr][nc] = 0\n","        \n","      elif self.state[nr][nc] == 0:\n","        before_num[i] = 0\n","        self.state[nr][nc] = 1\n","      \n","    for i in range(5):\n","      nr = row + dr[i]\n","      nc = col + dc[i]\n","      if before_num[i] == 2:\n","        continue\n","      if nr < 0 or nr >= 5 or nc < 0 or nc >= 5:\n","        continue\n","\n","      if self.state[nr][nc] != 0:\n","        isBingo = self.check_bingo(self.state,nr,nc)\n","        bingo_count = bingo_count + len(isBingo)\n","\n","        for dir in isBingo:\n","          if dir == \"ROW\":\n","            for i in range(5):\n","              self.state[nr][i] = 2\n","          elif dir == \"COL\":\n","            for i in range(5):\n","              self.state[i][nc] = 2\n","          elif dir == \"LC\":\n","            self.state[0][0] = 2\n","            self.state[1][1] = 2\n","            self.state[2][2] = 2\n","            self.state[3][3] = 2\n","            self.state[4][4] = 2\n","          elif dir == \"RC\":\n","            self.state[0][4] = 2\n","            self.state[1][3] = 2\n","            self.state[2][2] = 2\n","            self.state[3][1] = 2\n","            self.state[4][0] = 2\n","        \n","    \n","    three_bingo = True\n","    #rest_block_score = BFS(self.state,1,1) / 100\n","    #rest_block_score = BFS(self.state,1,1) / 50\n","    rest_block_score = BFS(self.state,1,1) / 10\n","\n","    if self.round % 3 == 0 and bingo_count == 0:\n","      three_bingo = False\n","    else:\n","      reward = rest_block_score\n","    #elif self.round % 3 == 0 and bingo_count > 0:\n","    #  reward = (2/bingo_count) + rest_block_score\n","    #elif self.round % 3 != 0 and bingo_count > 0:\n","    #  reward = -0.5 * bingo_count + rest_block_score\n","    #else:\n","    #  reward = rest_block_score\n","\n","    board_sum = 0\n","    for i in range(5):\n","      for j in range(5):\n","        board_sum = board_sum + self.state[i][j]\n","\n","    if (board_sum == 50) or self.round == 9 or three_bingo == False:\n","      done = True\n","      if self.round == 9 and three_bingo == True:\n","        reward = rest_block_score\n","      else:\n","        reward = -100\n","    else:\n","      done = False\n","    \n","    #if done == False:\n","    #  reward += 1\n","\n","    info ={}\n","    self.state = np.append(self.state.reshape(25),self.round)\n","    return self.state, reward, done, info\n","\n","  def render(self):\n","    print(\"ROUND : \",self.state[-1])\n","    print(tabulate(self.state[0:25].reshape(5,5)))\n","\n","  def reset(self):\n","    self.state = np.zeros(26)\n","    \n","    self.first_rand_pos = random.choice([i for i in range(0,25) if i not in [6]])\n","    self.second_rand_pos = random.choice([i for i in range(0,25) if i not in [6,self.first_rand_pos]])\n","    self.state[self.first_rand_pos] = 1\n","    self.state[self.second_rand_pos] = 1\n","    return self.state"],"metadata":{"id":"E3Vt5pzCsMsv","executionInfo":{"status":"ok","timestamp":1655940166120,"user_tz":-540,"elapsed":282,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["\n","test_state = np.zeros(26)\n","test_first_rand_pos = random.choice([i for i in range(0,25) if i not in [6]])\n","test_second_rand_pos = random.choice([i for i in range(0,25) if i not in [6,test_first_rand_pos]])\n","test_state[test_first_rand_pos] = 1\n","test_state[test_second_rand_pos] = 1\n","\n","t = TestBingoEnv(test_state)\n","t.render()\n","#tt = TestBingoEnv(np.array([1,0,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,1,0,0,0,2]))\n","#tt.render()\n","#tt_state,_,_,_ = tt.step(6)\n","#print(tt_state[0:25].reshape(5,5))\n","\n","#\n","#ROUND :  0.0\n","#-  -  -  -  -\n","#0  0  0  0  0\n","#0  0  0  0  0\n","#0  1  0  0  0\n","#0  1  0  0  0\n","#0  0  0  0  0\n","#-  -  -  -  -\n","# 이 경우 saved_model_14round 잘작동"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mN7qh0A2tHRh","outputId":"90b5a1fd-8e8a-4b85-c0a0-61fe51541ab0","executionInfo":{"status":"ok","timestamp":1655940185754,"user_tz":-540,"elapsed":5,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["ROUND :  0.0\n","-  -  -  -  -\n","0  0  0  0  0\n","0  0  0  0  0\n","1  0  0  0  0\n","0  0  0  1  0\n","0  0  0  0  0\n","-  -  -  -  -\n"]}]},{"cell_type":"code","source":["#반복\n","print(\"before\")\n","print(t.state[0:25].reshape(5,5))\n","cell_num = np.argmax(model.predict(t.state.reshape(1,1,26)))\n","temp_state,tmp_reward,tmp_done,_ = t.step(cell_num)\n","\n","print('ROUND : ',temp_state[-1])\n","print('cell_num : ',cell_num)\n","print(\"action : \",cell_num //5 , cell_num %5)\n","print(temp_state[0:25].reshape(5,5))\n","print(tmp_reward,tmp_done)\n","print(\"-------------------------------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V6WVU9O4Y4V8","outputId":"0885a760-7b64-4003-a5f1-974b193da2db","executionInfo":{"status":"ok","timestamp":1655940201748,"user_tz":-540,"elapsed":3,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["before\n","[[0. 0. 0. 0. 2.]\n"," [0. 0. 0. 2. 2.]\n"," [2. 2. 2. 2. 2.]\n"," [0. 2. 1. 0. 2.]\n"," [2. 2. 2. 2. 2.]]\n","ROUND :  9.0\n","cell_num :  6\n","action :  1 1\n","[[0. 2. 0. 0. 2.]\n"," [2. 2. 2. 2. 2.]\n"," [2. 2. 2. 2. 2.]\n"," [0. 2. 1. 0. 2.]\n"," [2. 2. 2. 2. 2.]]\n","0.0 True\n","-------------------------------\n"]}]},{"cell_type":"code","source":["print(BFS([[1, 1, 0, 0, 2],\n"," [1, 0, 1, 2, 2],\n"," [0, 0, 2, 1, 2],\n"," [2, 2, 2, 2, 2],\n"," [2, 2, 2, 2, 2],],1,1))\n","\n","print(BFS([[0, 0, 1, 0, 0],\n"," [0, 0, 0, 1, 0],\n"," [0, 0, 0, 1, 1],\n"," [1, 0, 0, 0, 0],\n"," [1, 1, 0, 0, 0]],1,1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ctYMcjYVCrHP","outputId":"12eb1c47-3ce7-40f2-9b30-60f457d547f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["75\n","195\n"]}]},{"cell_type":"code","source":["tmp_actions = model.predict(np.array([0, 0, 0, 0, 0,\n"," 0, 0, 0, 0, 0,\n"," 0, 0, 0, 0, 0,\n"," 1, 0, 0, 0, 0,\n"," 0, 1, 0, 0, 0, 0]).reshape(1,1,26))\n","print(tmp_actions)\n","tmp_num = np.argmax(tmp_actions)\n","print(tmp_num//5,tmp_num%5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J4M_cwzlObkM","outputId":"0b0a0956-2f39-461c-a215-0b569ed78ebe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ -81.620514  -94.453835  -81.42285   -80.62964   -80.356995  -94.5878\n","   -98.66935   -95.862755  -81.02263   -80.79095   -79.92034   -90.25046\n","   -81.07934   -80.87428   -80.09678   -79.64154   -79.9207    -79.938736\n","   -88.60145   -83.07046   -79.84846   -80.0151    -93.35611  -107.32624\n","   -96.846436]]\n","3 0\n"]}]},{"cell_type":"code","source":["#del model\n","import tensorflow as tf\n","model = tf.keras.models.load_model('electron_model_v3.h5')"],"metadata":{"id":"U_wRRluD3jMa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dqn = build_agent(model, actions)\n","dqn.compile(Adam(learning_rate=1e-3), metrics=[\"mse\"])"],"metadata":{"id":"Cb4T6mcK4Px8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with tf.device('/device:GPU:0'):\n","  dqn.fit(env,nb_steps = 10000, visualize= False, verbose=1)"],"metadata":{"id":"EEqgB_1yGIJ3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7919a80a-4b1e-4bf7-cba2-f92399ca92a6","executionInfo":{"status":"ok","timestamp":1649482463790,"user_tz":-540,"elapsed":14215,"user":{"displayName":"GH K","userId":"01062405385549991714"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training for 1000 steps ...\n","Interval 1 (0 steps performed)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]},{"output_type":"stream","name":"stdout","text":["\r    1/10000 [..............................] - ETA: 37:40 - reward: 63.0000"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n","  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"]},{"output_type":"stream","name":"stdout","text":["  997/10000 [=>............................] - ETA: 2:03 - reward: 40.3380done, took 13.897 seconds\n"]}]},{"cell_type":"code","source":["model.save(\"electron_model_v3.h5\")"],"metadata":{"id":"6aPUsWir-mH_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["reward 수정"],"metadata":{"id":"509m24G6cVVJ"}},{"cell_type":"code","source":["from tensorflow.python.client import device_lib\n","#print(device_lib.list_local_devices())\n","\n","\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApQiwXvgcSFN","outputId":"13690bbe-059b-40ad-fbe5-bfd6efe24605"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","source":["from rl.agents import DQNAgent\n","from rl.policy import BoltzmannQPolicy\n","from rl.memory import SequentialMemory\n","tf.debugging.set_log_device_placement(True)\n","with tf.device('/GPU:0'):\n","  gpu_model = Sequential()\n","  gpu_model.add(Flatten(input_shape=(1,26)))\n","  gpu_model.add(Dense(50, activation='relu'))\n","  gpu_model.add(Dense(50, activation='relu'))\n","  gpu_model.add(Dense(actions,activation='linear'))\n","  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n","  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n","\n","  c = tf.matmul(a, b)\n","  print(c)  \n","  gpu_model.summary()\n","  print(gpu_model)\n","  \n","  gpu_policy = BoltzmannQPolicy()\n","  gpu_memory = SequentialMemory(limit=50000,window_length=1)\n","  gpu_dqn = DQNAgent(model= gpu_model, memory = gpu_memory, policy= gpu_policy, nb_actions=actions, nb_steps_warmup=10,target_model_update=1e-2)\n","  gpu_dqn.compile(Adam(learning_rate=1e-3), metrics=[\"mae\"])\n","\n","  gpu_dqn.fit(env,nb_steps = 10000, visualize= False, verbose=1)\n","\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hcHdweDmyduM","outputId":"eb3dedb3-d65f-4e13-bff3-c095c3b39f9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor(\"MatMul_7:0\", shape=(2, 2), dtype=float32, device=/device:GPU:0)\n","Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_7 (Flatten)         (None, 26)                0         \n","                                                                 \n"," dense_21 (Dense)            (None, 50)                1350      \n","                                                                 \n"," dense_22 (Dense)            (None, 50)                2550      \n","                                                                 \n"," dense_23 (Dense)            (None, 25)                1275      \n","                                                                 \n","=================================================================\n","Total params: 5,175\n","Trainable params: 5,175\n","Non-trainable params: 0\n","_________________________________________________________________\n","<keras.engine.sequential.Sequential object at 0x7f596a4d0d50>\n","Training for 10000 steps ...\n","Interval 1 (0 steps performed)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]},{"output_type":"stream","name":"stdout","text":["\r    1/10000 [..............................] - ETA: 43:10 - reward: 0.7000"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n","  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"]},{"output_type":"stream","name":"stdout","text":[" 3902/10000 [==========>...................] - ETA: 1:44 - reward: -30.2383done, took 67.355 seconds\n"]}]},{"cell_type":"code","source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D0A6JUc1z78A","outputId":"ac0dcf11-9753-4f95-cabf-d5187eb0ec9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 10666592694238258993\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 11320098816\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 7164466880925710482\n","physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n","xla_global_id: 416903419\n","]\n"]}]},{"cell_type":"code","source":["!pip install tensorflowjs"],"metadata":{"id":"YYyzAHYj13j9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650707644982,"user_tz":-540,"elapsed":3963,"user":{"displayName":"GH K","userId":"01062405385549991714"}},"outputId":"5b6a54e9-ba05-4f99-e8ce-8e2e524a6c62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflowjs\n","  Downloading tensorflowjs-3.15.0-py3-none-any.whl (77 kB)\n","\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.8.0)\n","Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n","Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (0.12.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.17.3)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.8.0.dev2021122109)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.8.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (13.0.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.44.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.14.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.0.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.21.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (57.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.8.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.5.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.24.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (4.1.1)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.35.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3,>=2.1.0->tensorflowjs) (3.2.0)\n","Installing collected packages: tensorflowjs\n","Successfully installed tensorflowjs-3.15.0\n"]}]},{"cell_type":"code","source":["model.save(\"test.h5\")"],"metadata":{"id":"e4bSkaCy2C7L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!tensorflowjs_converter --input_format keras ./test.h5 ./"],"metadata":{"id":"7r41CF8f19m1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflowjs as tfjs\n","\n","tfjs.converters.save_keras_model(model, \"./\")"],"metadata":{"id":"t7ShOgLC7JGu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"1ZD1CHe2F6em"},"execution_count":null,"outputs":[]}]}